# Lezione 9 - Giochi ad informazione parziale + Agenti logici
Marted√¨ 29 Ottobre 2019

## Giochi ad informazione parziale

In questa tipologia di giochi non si hanno tutte le informazioni riguardo le mosse che pu√≤ fare l'avversario (esempio tipico sono i giochi di carte).

C'√® stata la proposta di ridurre questi giochi in giochi non deterministici, considerando tutte le possibili smazzate come se si avesse un dado con tante facce.

Un esempio di questo approccio √® dato da GIB, un programma che gioca a bridge. 
Il Bridge mostrato sulle slide √® un esempio semplificato, supponendo che i giocatori giochino a carte scoperte e che il giocatore min deve rispondere con lo stesso seme della carta gettata da max, e viceversa

Questa strategia funziona, ma non √® corretta.

Perch√© nel caso di informazione parziale una strategia ottima potrebbe fare delle mosse solamente per acquisire ulteriori informazioni, mentre nel caso non deterministico questa tipologia di mosse non viene presa in considerazione in quanto si da per scontato di avere a diposizione tutta l'informazione.

√à pi√π corretto che il valore di un azione dipenda dallo stato di informazione o **stato di credenza** in cui si trova l'agente ed √® possibile generare e ricercare all'interno di un albero di stati di credenza.

Questo conduce a comportamenti razionali quali:

- Agire con lo scopo di ottenere informazione;
- Trasmettere informazione al proprio compagno di gioco (come i motti nella briscola);
- Agire in modo casuale per minimizzare la perdita di informazione (fornire informazioni agli avversari).


## Agenti logici

![](./immagini/l2-agente-goal.png)

## Base di conoscenza

Un agente logico √® composto da due componenti __separate__ che possono essere modificati:

- **Inference Engine** (motore inferenziale): √® indipendete dal dominio applicativo e permette di utilizzare un linguaggio dichiarativo in quanto √® in grado di andare a valutare dei simboli.
- **Knowledge base** (base di conoscenza): contiene le informazioni specifiche del problema.

Queste due parti sono tra loro intercambiabili, lo stesso motore inferenziale pu√≤ essere utilizzato in pi√π domini specifici e allo stesso modo la stessa base di conoscenza pu√≤ essere trattata da vari tipi di motori inferenziali.

**Base di conoscenza**: insieme di sentenze espresse in un linguaggio formale che permette di utilizzare un approccio dichiarativo per definire degli agenti logici.

Le formule o sentenze contenute nella base di conoscenza di un agente rappresentano configurazioni fisiche di una parte dell‚Äôagente stesso, il ragionamento svolto dall'agente coinvolger√† la generazione e manipolazione di tali configurazioni.

Tutte le sentenze contenute nella base di conoscenza possono essere espresse come un'unica congiunzione, in questo modo si assume che tutta l'informazione presente nella base di conoscenza sia vera.

Sulla base di conoscenza √® possibile eseguire un `Tell` o `Dire` per aggiungere informazioni alla base di conosceza oppure √® possibile andare a cercare delle inforazioni `Ask` o `Chiedere`.

Ogni agente pu√≤ essere descritto a *livello di conoscenza* cio√® per quello che sa e indipendentemente dall'implementazione oppure a *livello implementativo* cos√¨ considerando le stutture dati e gli algoritmi che le manipolano.

## Agente bastato sulla conoscenza

```
funciton KB-Agente(percezione) retruns una azione
    static: KB, una base di conoscenza
            t, un contatore inizializzato a 0 che indica il tempo
    Tell(KB, CostruisciFormulaPercezione(percezione, t))
    azione <- Ask(KB, CostruisciInterrogazioneAzione(t))
    Tell(KB, CostruisciForumlaAzione(azione, t)
    t <- t +1
    return azione
```

L'agente deve essere capace di:

- Rappresentare stati, azioni, ecc.
- Incorporare nuove percezioni
- Aggiornare le rappresentazioni interne del mondo (ambiente)
- Dedurre propriet√† nascoste del mondo
- Dedurre le azioni appropriate da intraprendere

## Il magico mondo dei Wumpus

**PEAS**: Performance Enviroment "Attuatori" Sensors, sono le caratteristiche di valutazione di un ambiente.

**Misura della prestazione**: +1000 Oro, -1000 Morte, -1 per ogni spostamento, -10 per l'uso della freccia.

**Ambiente**: Scacchiera 4x4 con determinate caratteristiche (vedi slide)

**Attuatori**: Spostamento a DX/SX/UP/DOWN, prendi, lascia, lancia freccia.

**Sensori**: Brezza, Luccichio, Puzza.

Questo ambiente:

- **Non √® osservabile**: si hanno solo percezioni locali per la casella su cui ci si trova.
- **Deterministico**: i risultati delle azioni sono specificati.
- **Episodico**: no, √® necessario scegliere una sequenza di azioni.
- **Statico**: sia il Wumpus sia le trappole non si muovono.
- **Discreto**
- **Agente singolo**: il Wumpus fa parte dell'ambiente.

Per muoversi nell'ambiente l'agente deve valutare se √® sicuro spostarsi in una determinata cella in base alle percezioni che ha nello stato corrente.

In base a queste percezioni deve essere in grado di inferire quali sono le mosse sicure per poi sceglierne una di queste.

In alcune situazioni non √® possibile andare ad inferire la pericolosit√† di una mossa, in questo caso √® necessario passare all'**inferenza probabilitstica**. (Vado a caso ma con il buon senso).

In altri scenari, come quando subito all'inizio si percepisce la puzza del Wumpus, si possono usare strategia di **coercizione**.
In questo caso si sa che c'√® un Wumpus vicino e si lancia una freccia. Se dove ho lanciato la freccia c'era il Wumpus, questo ora √® morto ed √® possibile andarci, se invece la freccia √® andata a vuoto, ho solamente sprecato la freccia ma ho la certezza che il quadrato √® sicuro.

## Modelli

I logici tipicamente pensano in termini di modelli, che formalmente sono mondi strutturati rispetto ai quali si pu√≤ valutare se un'affermazione √® vera o falsa.

Formalmente i modelli possibili non sono altro che tutti i modi in cui si possono assegnare i valori alle varie variabili presenti nella sentenza.

Diciamo che *m* √® un modello di una sentenza ùú∂ se ùú∂ √® vera in *m* e con *M(ùú∂)* indichiamo l'insieme di tutti i modelli di ùú∂.

Allora KB (la base di conoscenza) |= ùú∂ se e solo se *M(KB) ‚äÜ M(ùú∂)* (ùú∂ √® deducibile dalla base di conosceza).

Questo perch√© la KB pu√≤ essere vista come una concatenazione di varie sequenze.

Per verificare la deducibilit√† √® necessario andare ad enumerare tutte le possibili combinazioni. Il che vuol dire che se ùú∂ contiene *n* simboli √® necessario verificare tutte le 2<sup>*n*</sup> combinazioni.

Si assume sempre che la base di conoscenza sia vera. In questo modo si pu√≤ dedurre i letterali ùú∂ dalla base, da notare anche che se KB|=ùú∂ allora si sa che ùú∂ √® vera, per√≤ se KB|/=ùú∂ allora non si sa se ùú∂ √® vera o falsa.

**Implicazione logica**: tra due formule significa che una *segue logicamenete* l'altra (entailment), in notazione si usa il simbolo ùú∂|=ùú∑ e si dice che "ùú∂ **implica** ùú∑". La definizione formale di implicazione √® la seguete: ùú∂ implica ùú∑ se e solo se, in ogni modello in cui ùú∂ √® vera, anche ùú∑ lo √®.

L'**inferenza** invece √® il processo con il quale da una proposizione accolta come vera si passa ad una seconda proposizione la cui verit√† deriva dal contenuto della prima. L'inferenza √® quindi il processo che porta a trovare l'implicazione tra due formule.
 
### Modellazione per il Wumpus (lite)

P<sub>i,j</sub> = vero se c'√® una trappola in (i,j)

B<sub>i,j</sub> = vero se c'√® brezza in (i,j)

Codifica di alcune percezioni:

- not(P<sub>1,1</sub>)
- not(B<sub>1,1</sub>)
- B<sub>2,1</sub>

Codifica della brezza causata dalla trappole:

- B<sub>1,1</sub> sse (P<sub>1,2</sub>  \/ P<sub>2,1</sub> )
- B<sub>2,1</sub> sse (P<sub>1,1</sub>  \/ P<sub>2,2</sub>  \/ P<sub>3,1</sub>)
- ...

Con queste informazioni √® possibile andare a creare una tabella di verit√†, con le colonne per i vari letterali, le informazioni presenti nella base di conoscenza e una colonna per l'affermazione ùú∂<sub>1</sub> che vogliamo dedurre. La dimensione della tabella di verit√† √® di $2^{numero\_di\_letterali}$

![](./immagini/l11-tabella.png)

Per controllare l'inferenza di ùú∂<sub>1</sub> √® necessario andare a verificare tutti i possibili valori di verit√† (**model checking**).

### Inferenza per mezzo di enumerazione

Enumerazioni a scandaglio (depth first) di tutti i modelli, √® un algoritmo corretto e completo.

```
function TVImplica?(KB, ùú∂) returns true o false
    s <- una lista di simboli proposizioniali contenuti sia in KB che ùú∂
    return TVVerificaTutto(KB, ùú∂, s, [])

function TVVerificaTtto(KB, ùú∂, s, modello) returns true oppure false
    if Vuoto(s) then
        if CPVero(KB, modello) then 
            return CPVero(ùú∂, modello)
        else
            return true
    else do
        P <- Primo(s); resto <- Resto(s)
        return TVVerificaTutto(KB, a, resto, Estendi(P, true, modello)) and TVVerificaTutto(KB, ùú∂, resto, Estendi(P, false, modello))    
```

